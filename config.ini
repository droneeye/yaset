[data]

# ===================================================================
# DATA FILES
# ===================================================================

# -------------------------------------------------------------------
# TRAIN

# Path to the train file
train_file_path = /path/to/data/train.tab

# -------------------------------------------------------------------
# DEV

# Do you want to specify a dev file ('true' or 'false')?
use_dev_file = false

# If you want to use a dev file, specify the path to file.
# This will be ignored if the value of the previous parameter is 'false'.
dev_file_path = /path/to/data/dev.tab

# If you do not want to use a dev file, specify the percentage of the training instances that should be kept as
# development instances (float between 0 and 1)
dev_ratio = 0.2

# Do you want to use a random seed for the train/dev split (in the case you do not want to specify a dev file)
dev_use_random_seed = true

# If you want to use a random seed, specify the seed (integer).
# This will be ignored if the value of the previous parameter is 'false'.
dev_random_seed = 42

# -------------------------------------------------------------------
# DATA PREPROCESSING

# Do you want to lowercase the tokens (first column)? This will not affect character emebddings computation (if used).
lower_input = true

# Do you want to replace digits with "0" in the tokens?
replace_digits = true

# -------------------------------------------------------------------
# FEATURES

# Do you want to use other features besides the tokens?
use_features = false

# If you want to use other features, please specified the column IDs (0-indexed)
feature_columns = 1,2,3

# ===================================================================
# EMBEDDING MODEL
# ===================================================================

# Model type (only 'gensim' or 'word2vec' models are accepted)
embedding_model_type = gensim

# Path to the pretrained model
embedding_model_path = /path/to/data/gensim-model.pkl

# Is there a specific embedding for unknown tokens in the model you specified?
# If not, a random vector will be created before training.
map_unknown_token = false

# If there is a specific embedding for unknown tokens, please specify the label.
# This will be ignored if the value for the previous option is false.
unknown_token_id = #UNK#

# ===================================================================
# WORKING DIR
# ===================================================================

# Path where a timestamped working directory will be created
top_working_dir = /path/to/working/dir/

[training]

# Deep learning model ('bi-lstm-char-crf')
model_type = bi-lstm-char-crf

# Maximum number of iterations for training
max_iterations = 100

# Maximum number of iteration after the best score has been obtained
patience = 20

# Number of units in the main BiLSTM
hidden_layer_size = 256

# -------------------------------------------------------------------
# METRICS

# Metric used for dev performance measurement ('accuracy' or 'conll')
dev_metric = conll

# -------------------------------------------------------------------
# CHARACTER EMBEDDINGS

# Use character embeddings in the model. These embeddings are learned during network training.
use_char_embeddings = true

# Number of units in the character BiLSTM
char_hidden_layer_size = 25

# Character emebdding size
char_embedding_size = 8

# -------------------------------------------------------------------
# WORD EMBEDDINGS

# Do you want to continue the training of the word embeddings?
trainable_word_embeddings = True

# -------------------------------------------------------------------
# MISC

# Number of CPU cores to use during training (upper-bound)
cpu_cores = 4

# Mini-btach size used during training
batch_size = 256

# Dropout rate applied during training
dropout_rate = 0.5

# -------------------------------------------------------------------
# OPTIMIZATION ALGORITHM

# Optimization algorithm ('adam' or 'sgd')
opt_algo = sgd

# Initial learning rate
opt_lr = 0.01

# Use gradient clipping?
opt_gc_use = true
# Gradient clipping value
opt_gs_val = 5.0