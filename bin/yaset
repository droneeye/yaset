#!/usr/bin/env python
import argparse
import configparser
import importlib
import logging
import os
import shutil
import sys
import time

import pkg_resources

from yaset.data.reader import TrainData, TestData
from yaset.helpers.config import extract_params
from yaset.nn.train import train_model, apply_model
from yaset.tools import ensure_dir


def parse_feature_columns(value):
    """
    Parse feature parameter
    :param value: feature value (str)
    :return:
    """

    raw_parts = value.split(",")
    raw_parts = [item.strip(" ") for item in raw_parts]

    final_list = [int(item) for item in raw_parts]

    return final_list


def log_message(message):

    logging.info("{} {} {}".format(
        "=" * 10,
        message,
        "=" * (70 - len(message) - 2 - 10)
    ))


def main(parsed_configuration):

    # Loading parameter description files
    TRAINING_PARAMS_FILE = pkg_resources.resource_filename('yaset', 'desc/TRAINING_PARAMS_DESC.json')
    DATA_PARAMS_DESC_FILE = pkg_resources.resource_filename('yaset', 'desc/DATA_PARAMS_DESC.json')
    BILSTMCHARCRF_PARAMS_DESC_FILE = pkg_resources.resource_filename('yaset', 'desc/BILSTMCHARCRF_PARAMS_DESC.json')

    data_params = extract_params(parsed_configuration["data"], DATA_PARAMS_DESC_FILE)
    training_params = extract_params(parsed_configuration["training"], TRAINING_PARAMS_FILE)
    if training_params["model_type"] == "bilstm-char-crf":
        model_params = extract_params(parsed_configuration["bilstm-char-crf"], BILSTMCHARCRF_PARAMS_DESC_FILE)
    else:
        raise Exception("The model type you specified does not exist: {}".format(training_params["model_type"]))

    # Checking if the working directory specified in the configuration exists
    if not os.path.isdir(os.path.abspath(data_params.get("working_dir"))):
        raise NotADirectoryError("The top working directory you specified does not exist: {}".format(
            os.path.abspath(data_params.get("working_dir"))
        ))

    # Creating the current working directory based on the top working directory
    current_working_directory = os.path.join(
        os.path.abspath(data_params.get("working_dir")),
        "yaset-learn-{}".format(timestamp)
    )
    ensure_dir(current_working_directory)

    # Setting up a log file and adding a new handler to the logger
    log_file = os.path.join(current_working_directory, "{}.log".format(
        "yaset-learn-{}".format(timestamp)
    ))

    fh = logging.FileHandler(log_file, encoding="UTF-8")
    fh.setFormatter(log_format)
    log.addHandler(fh)

    # -----------------------------------------------------------
    # FEATURES - NOT FULLY IMPLEMENTED YET

    feature_columns = list()
    #
    # if parsed_configuration.getboolean("data", "use_features"):
    #     feature_columns = parse_feature_columns(parsed_configuration["data"]["feature_columns"])

    # -----------------------------------------------------------
    # LOADING AND CHECKING DATA FILES

    log_message("BEGIN - LOADING AND CHECKING DATA FILES")

    # Creating data object
    data = TrainData(working_dir=current_working_directory, data_params=data_params)

    # Checking file format
    data.check_input_files()

    log_message("END - LOADING AND CHECKING DATA FILES")

    # -----------------------------------------------------------
    # EMBEDDING LOADING AND PROCESSING

    log_message("BEGIN - EMBEDDING LOADING AND PREPROCESSING")

    embedding_model_type = data_params.get("embedding_model_type")

    if embedding_model_type is not "random":
        # Case where the model type is not random

        logging.info("Model type: {}".format(embedding_model_type))

        # Checking if the embedding model path does exist
        embedding_file_path = os.path.abspath(data_params.get("embedding_model_path"))

        if not os.path.isfile(embedding_file_path):
            raise FileNotFoundError("The embedding file you specified doesn't exist: {}".format(
                embedding_file_path
            ))

        logging.info("File path: {}".format(embedding_file_path))

        embedding_oov_strategy = data_params.get("embedding_oov_strategy")
        embedding_oov_map_token_id = None
        embedding_oov_replace_rate = None

        if embedding_oov_strategy == "map":
            embedding_oov_map_token_id = data_params.get("embedding_oov_map_token_id")

        elif embedding_oov_strategy == "replace":
            embedding_oov_replace_rate = data_params.get("embedding_oov_replace_rate")

        elif embedding_oov_strategy == "none":
            pass

        else:
            raise Exception("The OOV strategy you specified is not recognized: {}".format(embedding_oov_strategy))

        # Dynamic loading of embedding module. Allow to write custom modules for specific model formats.
        logging.info("Creating embedding object")
        embedding_module = importlib.import_module("yaset.embed.{}".format(embedding_model_type))
        embedding_class = getattr(embedding_module, "{}Embeddings".format(embedding_model_type.title()))
        embedding_object = embedding_class(embedding_file_path, embedding_oov_map_token_id)

        # Loading embedding matrix into embedding object
        logging.info("Loading matrix")
        embedding_object.load_embedding()

        if embedding_oov_strategy == "replace":
            logging.info("Building unknown token vector")
            embedding_unknown_item_id = embedding_object.build_unknown_token()

        elif embedding_oov_strategy == "map":
            logging.info("Unknown token vector already exists, skipping building new one (id={})".format(
                embedding_oov_map_token_id
            ))

        elif embedding_oov_strategy == "none":
            logging.info("No unknown token vector is build")

    else:
        # Random embedding will be supported in a later release
        raise Exception("Random embeddings are not supported yet")

    log_message("END - EMBEDDING LOADING AND PREPROCESSING")

    log_message("BEGIN - CREATING TFRECORDS FILES")

    data.create_tfrecords_files(embedding_object, oov_strategy=embedding_oov_strategy,
                                unk_token_rate=embedding_oov_replace_rate)

    log_message("END - CREATING TFRECORDS FILES")

    log_message("BEGIN - LEARNING MODEL")

    logging.debug("Current training parameters")
    for k, v in training_params.items():
        logging.debug("* {} = {}".format(k, v))

    train_model(current_working_directory, embedding_object, data, training_params, model_params)

    target_model_configuration_path = os.path.join(os.path.abspath(current_working_directory), "config.ini")
    shutil.copy(os.path.abspath(args.config), target_model_configuration_path)

    log_message("END - LEARNING MODEL")

    return current_working_directory


if __name__ == "__main__":

    parser = argparse.ArgumentParser()

    parser.add_argument("--debug", action='store_true')

    subparsers = parser.add_subparsers(title="Sub-commands", description="Valid sub-commands",
                                       help="Valid sub-commands", dest="subparser_name")

    # 'Learn' subparser used to learn a new model
    parser_learn = subparsers.add_parser('LEARN', help="Learn model on train data")
    parser_learn.add_argument("--config", help="Configuration file (.ini format)", dest="config", type=str,
                              required=True)

    # 'Apply' subparser used to apply a pretrained model
    parser_test = subparsers.add_parser('APPLY', help="Apply model on test data")
    parser_test.add_argument("--model-path", help="Path to the model", dest="model_path", type=str, required=True)
    parser_test.add_argument("--input-file", help="Path to the tabulated test file", dest="input_file", required=True)
    parser_test.add_argument("--working-dir", help="Path where a working directory will be created", dest="working_dir",
                             required=True)

    parser_config = subparsers.add_parser('CHECK-CONFIG', help="Performs configuration file checking."
                                                               "Error will be raised if value are not correctly set.")
    parser_config.add_argument("--config", help="Configuration file (.ini format)", dest="config", type=str,
                               required=True)

    args = parser.parse_args()

    # Timestamp for directory naming
    timestamp = time.strftime("%Y%m%d-%H%M%S")

    # LOGGING
    # ===============================================================
    # Logging to stdout

    log = logging.getLogger('')
    log_format = logging.Formatter("%(asctime)s %(levelname)s %(message)s")

    # Setting debug level
    if args.debug:
        log.setLevel(logging.DEBUG)
    else:
        log.setLevel(logging.INFO)

    # Toning down the verbosity of gensim (in both NORMAL and DEBUG modes)
    logging.getLogger('gensim').setLevel(logging.WARNING)

    # Adding a stdout handler
    ch = logging.StreamHandler(sys.stdout)
    ch.setFormatter(log_format)
    log.addHandler(ch)

    if args.subparser_name == "CHECK-CONFIG":

        # Check if config file does exist
        if not os.path.isfile(os.path.abspath(args.config)):
            raise FileNotFoundError("The configuration file you specified does not exist: {}".format(
                os.path.abspath(args.config)
            ))

        parsed_configuration = configparser.ConfigParser(allow_no_value=True)
        parsed_configuration.read(os.path.abspath(args.config))

        TRAINING_PARAMS_FILE = pkg_resources.resource_filename('yaset', 'desc/TRAINING_PARAMS_DESC.json')
        DATA_PARAMS_DESC_FILE = pkg_resources.resource_filename('yaset', 'desc/DATA_PARAMS_DESC.json')
        BILSTMCHARCRF_PARAMS_DESC_FILE = pkg_resources.resource_filename('yaset', 'desc/BILSTMCHARCRF_PARAMS_DESC.json')

        log_message("DATA PARAMETERS")

        data_params = extract_params(parsed_configuration["data"], DATA_PARAMS_DESC_FILE)
        for k, v in sorted(data_params.items()):
            logging.info("{}: {}".format(k, v))

        log_message("TRAINING PARAMETERS")

        training_params = extract_params(parsed_configuration["training"], TRAINING_PARAMS_FILE)
        for k, v in sorted(training_params.items()):
            logging.info("{}: {}".format(k, v))

        if training_params["model_type"] == "bilstm-char-crf":
            log_message("BILSTMCHARCRF MODEL PARAMETERS")
            bilstm_params = extract_params(parsed_configuration["bilstm-char-crf"], BILSTMCHARCRF_PARAMS_DESC_FILE)
            for k, v in sorted(bilstm_params.items()):
                logging.info("{}: {}".format(k, v))

        logging.info("Everything seems fine with your configuration file, you are ready to take off")

    elif args.subparser_name == "LEARN":

        # Check if config file does exist
        if not os.path.isfile(os.path.abspath(args.config)):
            raise FileNotFoundError("The configuration file you specified does not exist: {}".format(
                os.path.abspath(args.config)
            ))

        # Creating a configparser parser and parsing configuration
        parsed_configuration = configparser.ConfigParser(allow_no_value=True)
        parsed_configuration.read(os.path.abspath(args.config))

        _ = main(parsed_configuration)

    elif args.subparser_name == "APPLY":

        model_path = os.path.abspath(args.model_path)
        input_file = os.path.abspath(args.input_file)
        working_dir = os.path.abspath(args.working_dir)

        if not os.path.isdir(model_path):
            raise NotADirectoryError("The model path you specified does not exist: {}".format(model_path))

        if not os.path.isfile(input_file):
            raise FileNotFoundError("The input file you specified does not exist: {}".format(input_file))

        if not os.path.isdir(working_dir):
            raise NotADirectoryError("The working directory you specified does not exist: {}".format(working_dir))

        current_working_directory = os.path.join(working_dir, "yaset-apply-{}".format(timestamp))
        ensure_dir(current_working_directory)

        # Setting up a log file and adding a new handler to the logger
        log_file = os.path.join(current_working_directory, "{}.log".format(
            "yaset-apply-{}".format(timestamp)
        ))

        fh = logging.FileHandler(log_file, encoding="UTF-8")
        fh.setFormatter(log_format)
        log.addHandler(fh)

        log_message("BEGIN - LOADING AND CHECKING DATA FILES")

        data = TestData(input_file, working_dir=current_working_directory, train_model_path=model_path)

        data.check_input_file()

        log_message("END - LOADING AND CHECKING DATA FILES")

        log_message("BEGIN - CREATING TFRECORDS FILES")

        target_tfrecords_file_path = os.path.join(os.path.abspath(current_working_directory), "data.tfrecords")

        data.convert_to_tfrecords(input_file, target_tfrecords_file_path)

        log_message("END - CREATING TFRECORDS FILES")

        logging.info("{} BEGIN - APPLYING MODEL {}".format("=" * 10, "=" * 36))

        # Load config file used during training
        parsed_configuration = configparser.ConfigParser()
        parsed_configuration.read(os.path.join(model_path, "config.ini"))

        train_config = get_training_parameters(parsed_configuration)

        apply_model(current_working_directory, model_path, data, train_config)

        log_message("END - APPLYING MODEL")
