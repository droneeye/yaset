#!/usr/bin/env python
import argparse
import configparser
import importlib
import logging
import os
import sys
import time

from yaset.data.reader import TrainData
from yaset.tools import ensure_dir
from yaset.nn.train import train_model


def get_training_parameters(parsed_configuration):

    parameters = dict()

    parameters["max_iterations"] = int(parsed_configuration["training"]["max_iterations"])
    parameters["patience"] = int(parsed_configuration["training"]["patience"])
    parameters["hidden_layer_size"] = int(parsed_configuration["training"]["hidden_layer_size"])
    parameters["cpu_cores"] = int(parsed_configuration["training"]["cpu_cores"])
    parameters["batch_size"] = int(parsed_configuration["training"]["batch_size"])

    return parameters

if __name__ == "__main__":

    parser = argparse.ArgumentParser()

    parser.add_argument("--debug", action='store_true')

    subparsers = parser.add_subparsers(title="Sub-commands", description="Valid sub-commands",
                                       help="Valid sub-commands", dest="subparser_name")

    parser_learn = subparsers.add_parser('LEARN', help="Learn model")
    parser_learn.add_argument("--config", help="Configuration file (.ini format)", dest="config", type=str,
                              required=True)

    args = parser.parse_args()

    timestamp = time.strftime("%Y%m%d-%H%M%S")

    if args.debug:
        logging.basicConfig(stream=sys.stdout, level=logging.DEBUG, format='%(asctime)s %(levelname)s %(message)s')
        logging.getLogger('gensim').setLevel(logging.WARNING)
    else:
        logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')
        logging.getLogger('gensim').setLevel(logging.WARNING)

    if args.subparser_name == "LEARN":

        # Check if config file does exist
        if not os.path.isfile(os.path.abspath(args.config)):
            raise FileNotFoundError("The configuration file you specified doesn't exist: {}".format(
                os.path.abspath(args.config)
            ))

        parsed_configuration = configparser.ConfigParser(allow_no_value=False)
        parsed_configuration.read(os.path.abspath(args.config))

        if not os.path.isdir(os.path.abspath(parsed_configuration["data"]["top_working_dir"])):
            raise NotADirectoryError("The top working directory you specified does not exists: {}".format(
                parsed_configuration["data"]["top_working_dir"]
            ))

        current_working_directory = os.path.join(
            os.path.abspath(parsed_configuration["data"]["top_working_dir"]),
            "yaset-learn-{}".format(timestamp)
        )

        ensure_dir(current_working_directory)

        train_file_path = parsed_configuration["data"]["train_file_path"]
        dev_file_path = None
        test_file_path = None
        dev_ratio = None

        # EMBEDDING LOADING AND PROCESSING
        # ==============================================================================================================

        embedding_model_type = parsed_configuration["data"]["embedding_model_type"]

        logging.info("{} BEGIN - EMBEDDING LOADING AND PREPROCESSING {}".format("=" * 10, "=" * 15))

        if embedding_model_type is not "random":

            logging.info("Model type: {}".format(embedding_model_type))

            embedding_file_path = os.path.abspath(parsed_configuration["data"]["embedding_model_path"])
            if not os.path.isfile(embedding_file_path):
                raise FileNotFoundError("The embedding file you specified doesn't exist: {}".format(
                    embedding_file_path
                ))

            logging.info("File path: {}".format(embedding_file_path))

            logging.info("Creating embedding object")
            embedding_module = importlib.import_module("yaset.embed.{}".format(embedding_model_type))
            embedding_class = getattr(embedding_module, "{}Embeddings".format(embedding_model_type.title()))
            embedding_object = embedding_class(embedding_file_path)

            logging.info("Loading matrix")
            embedding_object.load_embedding()

            logging.info("Building unknown token vector")
            embedding_object.build_unknown_token()

        logging.info("{} END - EMBEDDING LOADING AND PREPROCESSING {}".format("=" * 10, "=" * 17))

        # LOADING AND CHECKING DATA FILES
        # ==============================================================================================================

        if parsed_configuration.getboolean("data", "use_dev_file"):
            dev_file_path = os.path.abspath(parsed_configuration["data"]["dev_file_path"])

        if parsed_configuration.getboolean("data", "use_test_file"):
            test_file_path = os.path.abspath(parsed_configuration["data"]["test_file_path"])

        if not dev_file_path:
            dev_ratio = float(parsed_configuration["data"]["dev_ratio"])

        logging.info("{} BEGIN - LOADING AND CHECKING DATA FILES {}".format("=" * 10, "=" * 19))

        data = TrainData(train_file_path, dev_data_file=dev_file_path, working_dir=current_working_directory,
                         dev_ratio=dev_ratio)

        data.check_input_files()

        logging.info("{} END - LOADING AND CHECKING DATA FILES {}".format("=" * 10, "=" * 21))

        logging.info("{} BEGIN - CREATING TFRECORDS FILES {}".format("=" * 10, "=" * 26))

        data.create_tfrecords_files(embedding_object)

        logging.info("{} END - CREATING TFRECORDS FILES {}".format("=" * 10, "=" * 28))

        logging.info("{} BEGIN - LEARNING MODEL {}".format("=" * 10, "=" * 36))

        train_config = get_training_parameters(parsed_configuration)
        train_model(current_working_directory, embedding_object, data, train_config)

        logging.info("{} END - LEARNING MODEL {}".format("=" * 10, "=" * 38))
